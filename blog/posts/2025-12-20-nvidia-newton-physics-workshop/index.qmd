---
title: "NVIDIA Newton Physics: GPU-Accelerated Simulation for Physical AI"
description: "Hands-on workshop exploring NVIDIA's Newton physics engine, Cosmos world foundation models, and the Isaac ecosystem for training embodied AI agents"
author: "Rajesh"
date: "2025-12-20"
categories: [nvidia, newton, physics-simulation, physical-ai, isaac-lab, workshop]
image: "images/05-what-is-newton.png"
draft: false
---

## Overview

Today I attended an NVIDIA workshop on **Newton Physics** - their new open-source GPU-accelerated physics simulation engine designed specifically for Physical AI development. The workshop was presented by Ninad Madhab from NVIDIA and covered the full stack from world foundation models to hands-on simulation.

::: {.callout-note}
## Workshop Details
- **Date**: December 20, 2025
- **Duration**: ~2 hours
- **Format**: Presentation + Hands-on Lab (Brev.dev cloud)
- **Presenter**: Ninad Madhab, NVIDIA
:::

## The Physical AI Stack

NVIDIA's vision for Physical AI involves multiple layers working together.

### 1. Cosmos World Foundation Models

![NVIDIA Cosmos World Foundation Models](images/01-cosmos-intro.png){fig-alt="NVIDIA Cosmos showing Predict, Transfer, and Reason components"}

NVIDIA Cosmos is a platform for developing world foundation models that understand and can predict physical world behavior:

| Component | Purpose |
|-----------|---------|
| **Cosmos Predict** | Generate future virtual world states from multi-modal inputs |
| **Cosmos Transfer** | Generate physics-aware virtual worlds conditioned by real world and 3D inputs |
| **Cosmos Reason** | Chain-of-thought reasoning for physical AI world state understanding |

#### Cosmos Curator Data Pipeline

![Cosmos Curator Data Processing Pipeline](images/08-cosmos-curator-data-pipeline.png){fig-alt="Cosmos Curator workflow from video decode to training data"}

The Cosmos Curator provides accelerated data processing and curation, reducing processing time from 3.4 years to just 40 days for 20 million hours of video.

![Cosmos Curator Pipeline Detail](images/09-cosmos-curator-pipeline-detailed.png){fig-alt="Detailed view of filtering stage with Shot Detector, Motion Quality, Overlay Text, and Video Type"}

### 2. The Robotics Data Challenge

![The Robotics Data Challenge](images/02-robotics-data-challenge.png){fig-alt="Scaling laws for Physical AI"}

One of the key insights from the workshop was the evolution of scaling laws in AI:

```
Perception AI → Generative AI → Agentic AI → Physical AI
```

Physical AI requires **three types of scaling**:

1. **Pre-training Scaling** - Internet video pre-training
2. **Post-training Scaling** - Human demonstration + synthetic data generation
3. **Test-time Scaling** - "Long thinking" for complex physical reasoning

![Robotics Data Challenge Scaling Laws](images/10-robotics-data-challenge-scaling-laws.png){fig-alt="Three scaling laws from Perception AI to Physical AI"}

### 3. Digital Twins & Synthetic Data

![Digital Twins in Physical AI](images/03-digital-twins.png){fig-alt="Digital Twin concept for robotics training"}

#### NVIDIA Omniverse Platform

![NVIDIA Omniverse Platform Overview](images/11-nvidia-omniverse-platform-overview.png){fig-alt="Omniverse architecture with APIs, services, and ecosystem connections"}

The Omniverse platform provides USD Write, USD Render, Omniverse Channel, App Streaming, SDKs, Operators, and Kit integration with various applications like Gazebo, Ansys, and Cadence.

![Isaac Sim Robotics Data Gap](images/12-isaac-sim-robotics-data-gap.png){fig-alt="Addressing the robotics data gap with synthetic data"}

![Omniverse Cosmos Synthetic Data Generation](images/13-omniverse-cosmos-synthetic-data-generation.png){fig-alt="Controllable synthetic data generation workflow"}

![Physical AI Approaches for Facilities](images/14-physical-ai-approaches-facilities.png){fig-alt="Inside-Out AI vs Outside-In AI approaches"}

Two approaches to applying Physical AI:

- **Inside-Out AI** - Digital Twin using NVIDIA Omniverse and Cosmos
- **Outside-In AI** - Vision AI Agents using NVIDIA Metropolis

## NVIDIA Isaac Platform

![NVIDIA Isaac Platform Architecture](images/15-nvidia-isaac-platform-architecture.png){fig-alt="Isaac architecture showing sensor inputs through neural networks to action output"}

![Isaac Robotics Development Workflow](images/16-isaac-robotics-development-workflow.png){fig-alt="Simulate-train-deploy workflow cycle"}

The NVIDIA Isaac platform provides:

- **Robot Foundation Models** - Pre-trained models for robotics tasks
- **Simulation Frameworks** - Physics simulation for training
- **Synthetic Data Generation Pipelines** - Data multiplication for training

### Isaac Perceptor for Mobile Robots

![Isaac Perceptor for Autonomous Mobile Robots](images/17-isaac-perceptor-autonomous-mobile-robots.png){fig-alt="Isaac Perceptor reference workflow with components"}

Isaac Perceptor is a reference workflow for developing autonomous mobile robots with:

- Disparity computation
- Visual Odometry
- People Segmentation
- 3D Occupancy Grid

All optimized to run on **NVIDIA Jetson** with Isaac ROS (30+ ROS packages, fully optimized).

### Isaac Manipulator

![Isaac Manipulator Overview](images/18-isaac-manipulator-overview.png){fig-alt="Manipulator reference workflow with 6D pose tracking and motion planning"}

Reference workflow for robot arms with 6D Pose Tracking, Motion Planning, Grasp Identification, and Manipulation & Dexterity capabilities.

### Isaac GROOT for Humanoids

![Isaac GROOT Overview](images/19-isaac-groot-overview.png){fig-alt="GROOT components: Foundation Models, Synthetic Data, Isaac Lab/Sim, Thor"}

GROOT provides:

- **Foundation Models** - Pre-trained for humanoid robots
- **Synthetic Motion and Data Generation Pipelines**
- **Isaac Lab and Isaac Sim** - Simulation environment
- **Thor Robotics Computer** - Hardware platform

### GROOT-Mimic Blueprint

![GROOT-Mimic Blueprint](images/04-groot-mimic-pipeline.png){fig-alt="GROOT-Mimic data pipeline from demonstrations to training data"}

![GROOT-Mimic Blueprint Detail](images/20-groot-mimic-blueprint.png){fig-alt="10s of demos to 1 million training examples"}

A fascinating data multiplication pipeline:

```
10s of demonstrations → 100s of synthetic motions → 1 Million training examples
```

The pipeline components:

- **GROOT-Teleop** (Isaac Lab) - Capture human demonstrations via teleoperation
- **GROOT-Mimic** (Isaac Lab) - Learn motion patterns from demonstrations
- **GROOT-Gen** (Omniverse + Cosmos) - Generate synthetic variations at scale

#### Isaac Lab Arena Tutorials

![G1 Loco-Manipulation Tutorial](images/21-g1-loco-manipulation-tutorial.png){fig-alt="G1 humanoid robot in warehouse simulation"}

![Workflow Prerequisites Setup](images/22-workflow-prerequisites-setup.png){fig-alt="Prerequisites and workflow steps for G1 tutorial"}

![Closed-Loop Policy Inference](images/23-closed-loop-policy-inference.png){fig-alt="Docker setup and Blackwell architecture notes"}

![GROOT Configuration Testing](images/24-groot-configuration-testing.png){fig-alt="Policy testing command with expected metrics"}

## Newton Physics Engine

The main focus of the hands-on portion was **Newton** - NVIDIA's new physics simulation engine.

### What is Newton?

![What is Newton?](images/05-what-is-newton.png){fig-alt="Newton overview slide showing key features and backers"}

![What is Newton Overview](images/38-what-is-newton-overview.png){fig-alt="Newton as GPU-accelerated physics simulation engine"}

Newton is a GPU-accelerated physics simulation engine built upon **NVIDIA Warp**, specifically targeting roboticists and simulation researchers.

**Key Characteristics:**

- **Open Source** - Apache 2.0 license
- **GPU-Accelerated** - Leverages NVIDIA Warp for fast, scalable simulation
- **Differentiable** - Supports gradient computation for machine learning
- **Modular** - Easily extensible with new solvers and components

**Backed by Industry Leaders:**

- Disney Research
- Google DeepMind
- NVIDIA
- The Linux Foundation

### Newton Design Principles

![Newton Design Principles](images/37-newton-design-principles-slide.png){fig-alt="Fidelity, Performance, and Modularity principles"}

![Newton Design Principles Detail](images/39-newton-design-principles.png){fig-alt="Four core design guidelines"}

Newton follows four core design guidelines:

1. **Separate physical model from numerical method** (AX+B=0)
2. **Flat data preferred** over object-oriented programming
3. **Avoid hidden state** for memory control
4. **Take what you need** at each level (FUNC/KERNEL/SOLVER abstraction)

### Core Features

| Feature | Description |
|---------|-------------|
| **Multiple Solvers** | XPBD, VBD, MuJoCo, Featherstone, SemiImplicit |
| **Rich Import/Export** | URDF, MJCF, USD file formats |
| **Modular Design** | Easy to extend with custom solvers |
| **Differentiable** | End-to-end gradient support for RL |

### Newton Architecture

![Newton Introduction Notebook](images/06-newton-introduction.png){fig-alt="Newton introduction Jupyter notebook showing key features"}

![Reference Simulation Pipeline](images/40-reference-simulation-pipeline.png){fig-alt="ModelBuilder to Solver workflow diagram"}

Newton follows a clean architectural pattern:

```python
import newton
import warp as wp
import numpy as np
from pxr import Usd, UsdGeom

# Key modules
import newton.examples
import newton.usd
import rerun as rr  # Visualization
```

![Newton Module Overview](images/41-newton-module-overview.png){fig-alt="Repository breakdown and module structure"}

![Newton Architecture Documentation](images/46-newton-architecture-documentation.png){fig-alt="Five core components of Newton architecture"}

The five core components:

1. **ModelBuilder** - Constructing models
2. **Model** - Encapsulating physical structure
3. **State** - Dynamic state representation
4. **Solver** - Physics simulation
5. **Viewer** - Visualization

### Key Concepts

#### 1. ModelBuilder

![Newton ModelBuilder Overview](images/44-newton-modelbuilder-overview.png){fig-alt="High-level scene building methods"}

![Building Model with ModelBuilder](images/47-building-model-with-modelbuilder.png){fig-alt="Step-by-step guide for constructing simulation scenes"}

Create articulated systems programmatically or import from standard formats:

```python
builder = newton.ModelBuilder()
builder.add_usd("cartpole.usd")

# Finalize and upload to GPU
model = builder.finalize()
```

![Add Mesh Body Step](images/48-add-mesh-body-step.png){fig-alt="Loading mesh from USD and finalizing model"}

#### 2. Model

![Newton Model System Description](images/42-newton-model-system-description.png){fig-alt="Flat Python struct of 1D, 2D Warp arrays"}

![Newton Model Detailed View](images/43-newton-model-detailed-view.png){fig-alt="Complete class definition with all attributes"}

The `newton.Model` is a flat Python struct of 1D, 2D Warp arrays that stores non-time varying data, supporting generalized and maximal coordinates.

#### 3. Articulations

![Articulations Introduction](images/54-articulations-introduction.png){fig-alt="Multi-body systems connected by joints"}

Multi-body systems connected by joints. Newton supports:

- **REVOLUTE (Hinge)** - Rotation around a single axis
- **PRISMATIC (Slider)** - Translation along a single axis
- **BALL (Spherical)** - Rotation in all directions
- **FIXED** - No relative motion (welded connection)
- **DISTANCE** - Maintains constant distance between points

#### 4. State Management

![Newton State Class Overview](images/55-newton-state-class-overview.png){fig-alt="State objects hold time-varying data"}

![Newton State Attributes Detail](images/56-newton-state-attributes-detail.png){fig-alt="Class definition with all state attributes"}

![Newton State Full Screen](images/57-newton-state-full-screen.png){fig-alt="Full-screen view of State class"}

The `newton.State` class holds all time-varying simulation data:

```python
class State:
    """Holds all time-varying data for a model."""

    # Joint state
    joint_q: wp.array   # Joint positions
    joint_qd: wp.array  # Joint velocities

    # Body state
    body_q: wp.array    # Body coordinates
    body_qd: wp.array   # Body velocities

    # Particle state
    particle_q: wp.array   # Particle positions
    particle_qd: wp.array  # Particle velocities
```

![Creating States and Control](images/49-creating-states-and-control.png){fig-alt="State, control, and contacts objects"}

#### 5. Control

![Newton Control API](images/58-newton-control-api.png){fig-alt="Control class for external forces and actuation"}

The `newton.Control` class manages external forces and actuation:

- Joint forces
- Position/velocity targets
- Triangle/tetrahedral element activations

#### 6. Simulation Loop

![Newton Code Example](images/07-newton-code-example.png){fig-alt="Newton code example putting it all together"}

![Code Example Simulation Loop](images/67-code-example-simulation-loop.png){fig-alt="Complete Newton simulation workflow"}

Putting it all together:

```python
import newton

# Import model from USD
builder = newton.ModelBuilder()
builder.add_usd("cartpole.usd")
model = builder.finalize()

# Create MuJoCo solver
solver = newton.solvers.SolverMuJoCo(model)

# Create state and control objects
state_0 = model.state()
state_1 = model.state()
control = model.control()
contacts = model.collide(state_0)

# Simulation loop
for i in range(num_steps):
    state_0.clear_forces()

    # Forward dynamics
    solver.step(
        model, state_0, state_1,
        control, contacts, sim_dt
    )

    # Swap states
    state_0, state_1 = state_1, state_0
```

![Jupyter Notebook Double Pendulum Code](images/66-jupyter-notebook-double-pendulum-code.png){fig-alt="Python code for creating double pendulum"}

#### 7. Solvers

![Setting Up Solver](images/50-setting-up-solver.png){fig-alt="Multiple solver implementations including XPBD"}

![Newton SolverBase API](images/65-newton-solverbase-api.png){fig-alt="SolverBase class step() method signature"}

Newton provides multiple solver implementations:

- **SolverXPBD** - Extended Position Based Dynamics (fast, stable)
- **SolverPBD** - Position Based Dynamics
- **SolverMuJoCo** - MuJoCo-compatible solver
- **SolverFeatherstone** - Articulated body algorithm
- **SolverSemiImplicit** - Semi-implicit integration

![Supported Features Solver Comparison](images/71-supported-features-solver-comparison.png){fig-alt="Table showing solver feature support"}

![Newton Physics Workflow Diagram](images/72-newton-physics-workflow-diagram.png){fig-alt="Data flow through solver.step()"}

#### 8. GPU Acceleration with CUDA Graphs

![GPU Acceleration CUDA Graphs](images/51-gpu-acceleration-cuda-graphs.png){fig-alt="Capturing simulation loop as CUDA graph"}

Reduce kernel launch overhead by capturing the simulation loop as a CUDA graph for optimized execution.

#### 9. Selection API

![Selection API Articulation Views](images/79-selection-api-articulation-views.png){fig-alt="Creating ArticulationViews for batched DOF operations"}

For reinforcement learning, we often need to select subsets of DOFs batched by environment:

```python
from newton.selection import ArticulationView

# Create view onto data for one articulation
ants = ArticulationView(model, "/World/envs/*/Robot/torso")

# Get strided joint arrays
ant_q = ants.get_attribute("joint_q", state_0)
ant_qd = ants.get_attribute("joint_qd", state_0)

# Set DOF states (masked)
ants.set_attribute("joint_q", state_0, xform, mask=mask)
ants.set_attribute("joint_qd", state_0, velocity, mask=mask)

# Helpers for manipulating root state
ants.set_root_transforms(state_0, xform, mask=mask)
ants.set_root_velocities(state_0, velocity, mask=mask)
```

### Geometry & Contacts

![Newton Geometry Library Overview](images/59-newton-geometry-library-overview.png){fig-alt="CollisionPipeline architecture"}

![Newton Geometry Collision Demo](images/60-newton-geometry-collision-demo.png){fig-alt="Collision detection with scattered blocks"}

![Newton Contacts API](images/61-newton-contacts-api.png){fig-alt="Contacts class for contact geometry"}

Newton includes sophisticated contact modeling via `newton.geometry`:

- **SDF-SDF collision detection** with multi-stage broadphase and narrow-band SDFs
- Meshes are converted to narrow-band SDFs
- Contact constraints generated from isosurface triangles
- Area-dependent scaling of MuJoCo constraint parameters
- **Contact reduction** finds representative points from thousands of generated contacts

### Hydroelastic Contacts

![Hydroelastic Contacts Overview](images/62-hydroelastic-contacts-overview.png){fig-alt="SDF-SDF collision detection with demos"}

![Hydroelastic Contacts Demo Frame 1](images/63-hydroelastic-contacts-demo-frame1.png){fig-alt="Robotic arm with contact visualization"}

![Hydroelastic Contacts Demo Frame 2](images/64-hydroelastic-contacts-demo-frame2.png){fig-alt="Dynamic color visualization of contacts"}

The demo showed the **Objaverse SDF grasping benchmark** at 1mm SDF resolution - all running in realtime!

### Advanced Solvers

#### MuJoCo Solver Performance

![MuJoCo Solver Performance Benchmarks](images/73-mujoco-solver-performance-benchmarks.png){fig-alt="Apptronk locomotion and LEAP hand benchmarks"}

Performance comparisons for Apptronk locomotion and LEAP hand manipulation on RTX 6000.

#### VBD Solver for Cloth

![VBD Solver Cloth Simulation](images/74-vbd-solver-cloth-simulation.png){fig-alt="Vertex-Block Descent method with cloth examples"}

Vertex-Block Descent method with rigid-body one-way coupling and upcoming cable simulation support.

#### MPM Solver for Granular Materials

![MPM Solver Granular Materials](images/75-mpm-solver-granular-materials.png){fig-alt="Material Point Method for granular materials"}

Implicit MPM implementation based on warp.fem - GPU-friendly solver for granular materials handling very stiff materials.

![MPM XPBD Two-Way Coupling Example](images/76-mpm-xpbd-two-way-coupling-example.png){fig-alt="Sand interaction with rigid bodies"}

Two-way coupling where XPBD and MPM solvers exchange forces and impulses explicitly.

### Inverse Kinematics

![Inverse Kinematics Performance](images/77-inverse-kinematics-performance.png){fig-alt="3-10x speedups over cuRobo and PyRoki"}

Newton's IK module provides 3-10x speedups over cuRobo and PyRoki with:

- Physics-aware objectives
- Levenberg-Marquardt and L-BFGS solvers
- Interactive OpenGL viewer

### Sensors

![Newton Sensors Overview](images/78-newton-sensors-overview.png){fig-alt="ContactSensor, RaycastSensor, TiledCameraSensor"}

Newton includes various sensor types:

- **ContactSensor** - Contact force sensing
- **RaycastSensor** - Lidar-style raycasting
- **TiledCameraSensor** - Depth camera simulation

### Custom Attributes & Extensions

![Custom Attributes Workflow](images/80-custom-attributes-workflow.png){fig-alt="Declare, Define, Use workflow"}

Three-step process for augmenting Newton data structures:

1. **Declare** - Define custom properties
2. **Define** - Implement behavior
3. **Use** - Access in simulation

![Extending Newton Methods](images/81-extending-newton-methods.png){fig-alt="Custom solvers, contact models, C++ plugins"}

Multiple methods for extending Newton:

- Custom solvers
- Contact models
- Integration with Warp and C++ plugins

## Hands-on Lab Environment

The workshop used **Brev.dev** for cloud-based GPU access:

![Brev CLI Setup Windows](images/28-brev-cli-setup-windows.png){fig-alt="Windows WSL installation instructions"}

![Brev CLI Setup Linux](images/31-brev-cli-setup-linux.png){fig-alt="Linux installation and shell access"}

![Newton Deployment Configuration](images/30-newton-deployment-configuration.png){fig-alt="Container and compute settings with L40S GPU"}

| Spec | Value |
|------|-------|
| GPU | NVIDIA L40S (44GB VRAM) |
| Cost | $1.89/hour |
| Region | N. Virginia (AWS) |

![Instance Running Open Notebook](images/34-instance-running-open-notebook.png){fig-alt="Newton instance status page"}

![JupyterLab Launcher Interface](images/36-jupyterlab-launcher-interface.png){fig-alt="JupyterLab with newton and gds-nvidia-fs folders"}

**Tutorial Notebooks:**

1. `00_introduction.ipynb` - Newton basics
2. `01_articulations.ipynb` - Joint systems
3. `02_inverse_kinematics.ipynb` - IK solving
4. `03_joint_control.ipynb` - Control strategies
5. `04_domain_randomization.ipynb` - Sim-to-real transfer
6. `05_robot_policy.ipynb` - RL policy training
7. `06_diffsim.ipynb` - Differentiable simulation

![Introduction to Newton Physics Notebook](images/45-introduction-to-newton-physics-notebook.png){fig-alt="Jupyter notebook view of introduction"}

![Differentiable Simulation Tutorial](images/32-differentiable-simulation-tutorial.png){fig-alt="Tutorial on differentiable simulation"}

### Simulation Results

![Summary and Next Steps](images/52-summary-and-next-steps.png){fig-alt="Essential Newton workflow summary"}

![Simulation Viewer Output](images/53-simulation-viewer-output.png){fig-alt="3D viewer showing bunny mesh simulation"}

![Jupyter Notebook Simulation](images/83-jupyter-notebook-simulation.png){fig-alt="Quadruped robots in simulation"}

::: {.callout-important}
## Blackwell Architecture Note
The GROOT N1.5 codebase does not yet support running on Blackwell architecture (RTX 50 series, RTX Pro 6000, DGX Spark). Use the **Base + GROOT** container for policy post-training and evaluation on Blackwell GPUs.
:::

## Isaac Lab Arena

For policy evaluation, NVIDIA provides **Isaac Lab Arena** - a framework for closed-loop policy inference:

![Isaac Lab Arena Documentation Home](images/92-isaaclab-arena-documentation-home.png){fig-alt="Release version with humanoid robot demo"}

![Isaac Lab Arena GitHub Repository](images/91-isaaclab-arena-github-repository.png){fig-alt="Public repository with 95 stars"}

### Tasks Design

![Tasks Design Documentation](images/93-tasks-design-documentation.png){fig-alt="Core architecture explanation"}

![TaskBase Class Methods Detail](images/94-taskbase-class-methods-detail.png){fig-alt="Abstract method decorators"}

Tasks are defined using the `TaskBase` abstract class:

```python
class TaskBase(ABC):
    @abstractmethod
    def get_scene_cfg(self) -> Any:
        """Additional scene configurations."""

    @abstractmethod
    def get_termination_cfg(self) -> Any:
        """Success and failure conditions."""

    @abstractmethod
    def get_events_cfg(self) -> Any:
        """Reset and randomization handling."""

    @abstractmethod
    def get_metrics(self) -> list[MetricBase]:
        """Performance evaluation metrics."""

    @abstractmethod
    def get_mimic_env_cfg(self, embodiment_name: str) -> Any:
        """Demonstration generation configuration."""
```

![Closed-Loop Policy Inference Tutorial](images/95-closed-loop-policy-inference-tutorial.png){fig-alt="GR1 Open Microwave Door Task workflow"}

Example workflows include:

- G1 Loco-Manipulation Box
- Pick and Place Task
- **GR1 Open Microwave Door Task**

## ROS Integration

![GitHub Isaac Sim ROS Workspaces](images/85-github-isaac-sim-ros-workspaces.png){fig-alt="humble_ws/src directory structure"}

![GitHub Carter Navigation Folder](images/86-github-carter-navigation-folder.png){fig-alt="Carter navigation launch, maps, params folders"}

![Isaac Sim Carter Navigation Repo](images/89-isaac-sim-carter-navigation-repo.png){fig-alt="IsaacSim-ros_workspaces updates for Isaac Sim 6.0.0"}

### ROS2 NanoLLM

![GitHub ROS2 NanoLLM Repository](images/87-github-ros2-nanollm-repository.png){fig-alt="ROS2 nodes for LLM, VLM, and VLA"}

![ROS2 NanoLLM GitHub README](images/88-ros2-nanollm-github-readme.png){fig-alt="Setup instructions for NanoLLM on Jetson Orin"}

ROS2 nodes for LLM, VLM, and VLA using NanoLLM optimized for NVIDIA Jetson Orin.

## Newton Repository

![Newton Physics GitHub Repository](images/68-newton-physics-github-repository.png){fig-alt="Repository folder structure"}

![Newton Examples Gallery](images/69-newton-examples-gallery.png){fig-alt="Robot and cloth simulation examples"}

![Installation System Requirements](images/70-installation-system-requirements.png){fig-alt="Python 3.10+, NVIDIA GPU compute 5.0+"}

### System Requirements

- Python 3.10+
- NVIDIA GPU compute capability 5.0+
- Platform-specific requirements for ARM64

## Summary & Next Steps

![Summary Next Steps](images/82-summary-next-steps.png){fig-alt="Newton repository link and QR code"}

## Key Takeaways

1. **Newton is production-ready** - Open source, backed by major players, actively developed

2. **MuJoCo integration** - Newton can use MuJoCo as a solver backend, bringing the best of both worlds

3. **Differentiable by design** - Every component supports gradient computation for end-to-end learning

4. **USD-native** - Deep integration with Universal Scene Description for Omniverse compatibility

5. **Scaling is the key** - The GROOT-Mimic pipeline shows how to go from 10 demos to 1M training examples

## Next Steps

Based on this workshop, I plan to:

1. **Try Newton locally** - Install and run the tutorial notebooks on my RTX 5090
2. **Integrate with Isaac Lab** - Use Newton as an alternative physics backend
3. **Explore GROOT-Mimic** - Test the demonstration multiplication pipeline
4. **Build custom environments** - Create Newton-based tasks for Go2-W training

## Community Resources

![NVIDIA Omniverse Discord Announcement](images/96-nvidia-omniverse-discord-announcement.png){fig-alt="Discord community invitation"}

![Workshop Links Notepad](images/98-workshop-links-notepad.png){fig-alt="Google Meet URL and contact information"}

## Resources

- [Newton GitHub Repository](https://github.com/nvidia/newton) (Apache 2.0)
- [NVIDIA Warp](https://github.com/NVIDIA/warp) - The underlying GPU compute framework
- [Isaac Lab Arena Documentation](https://isaac-sim.github.io/IsaacLab-Arena/)
- [Brev.dev](https://brev.nvidia.com) - Cloud GPU platform for hands-on labs

---

*This workshop was part of NVIDIA's ongoing Physical AI education series. The combination of Cosmos, Newton, and Isaac Lab represents a comprehensive stack for developing embodied AI agents.*
