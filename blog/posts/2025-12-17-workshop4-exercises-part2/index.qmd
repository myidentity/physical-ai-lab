---
title: "Workshop 4 Preview: Vision Alone - When the Camera Goes Blind"
subtitle: "Part 2 of 4: Why Visual Odometry Fails and What IMU Can't See"
author: "Rajesh"
date: "2025-12-17T13:00:00"
categories: [ros2, visual-odometry, perception, workshop, roscon-india, realsense, d435i, rtabmap]
image: "thumbnail.png"
toc: true
toc-depth: 3
code-fold: true
code-summary: "Show code"
lightbox: true
---

## The Story So Far

In [Part 1](../2025-12-17-workshop4-exercises-part1/), we experienced the limitations of IMU-only sensing:

| Problem | Impact |
|---------|--------|
| No raw orientation | Need Madgwick filter |
| Yaw drift (no magnetometer) | Unbounded heading error |
| Position drift | Meters of error in seconds |
| Calibration required | Extra setup work |

**The conclusion**: IMU alone isn't enough for robot navigation.

But wait - the D435i has **cameras** too! Can visual odometry solve these problems?

---

## What This Part Covers

Now we'll try **vision-only** approaches and discover their own failure modes.

| Experiment | Test | Problem Discovered |
|------------|------|-------------------|
| **8** | Visual Odometry | Fast motion = tracking loss |
| **9** | Textureless Surfaces | No features = no tracking |
| **10** | Lighting Changes | Exposure changes = drift |

::: {.callout-important}
## The Key Insight Coming
IMU fails where vision succeeds, and vision fails where IMU succeeds. This is why **fusion** (Part 3) is the answer!
:::

---

## Setting Up Visual Odometry

### Launch RTAB-Map Visual Odometry

RTAB-Map includes a powerful visual odometry module that works with RGB-D cameras like the D435i.

```bash
# Terminal 1: Launch RealSense camera
ros2 launch realsense2_camera rs_launch.py \
    enable_gyro:=true \
    enable_accel:=true \
    unite_imu_method:=2 \
    align_depth.enable:=true

# Terminal 2: Launch RTAB-Map visual odometry ONLY (no IMU yet!)
ros2 launch rtabmap_launch rtabmap.launch.py \
    args:="--delete_db_on_start" \
    rgb_topic:=/camera/camera/color/image_raw \
    depth_topic:=/camera/camera/aligned_depth_to_color/image_raw \
    camera_info_topic:=/camera/camera/color/camera_info \
    frame_id:=camera_link \
    approx_sync:=true \
    visual_odometry:=true \
    imu_topic:=""
```

### Verify It's Working

```bash
# Terminal 3: Check odometry output
ros2 topic echo /odom --field pose.pose.position

# Terminal 4: Launch RViz2
rviz2
# Add: TF, PointCloud2 (/rtabmap/cloud_map), Odometry (/odom)
```

When working, you should see position updates as you move the camera:

```yaml
position:
  x: 0.12
  y: -0.05
  z: 0.03
```

---

## Experiment 8: Fast Motion = Lost Tracking

### What You'll Experience

Visual odometry relies on **feature matching** between consecutive frames. When motion is too fast, features blur and matching fails!

### The Test

```bash
# Monitor odometry while testing
ros2 topic hz /odom
ros2 topic echo /odom --field pose.pose.position
```

### Procedure

1. Hold camera steady - observe stable tracking
2. Move camera slowly - observe smooth odometry
3. **Shake camera rapidly** for 2 seconds
4. Stop and observe

### What Happens

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VISUAL ODOMETRY vs FAST MOTION                        â”‚
â”‚                                                                         â”‚
â”‚    Frame N          Frame N+1 (motion blur)      Frame N+2             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    â”‚ â˜…  â˜…    â”‚      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚         â”‚    â˜…  â˜… â”‚           â”‚
â”‚    â”‚    â˜…    â”‚  â”€â”€â–º â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚  â”€â”€â–º   â”‚  â˜…      â”‚           â”‚
â”‚    â”‚  â˜…   â˜…  â”‚      â”‚ ~~~~~~~~~~~~~~~~ â”‚         â”‚     â˜…  â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚    Clear features   Motion blur!                 New features          â”‚
â”‚                     No matches! ğŸ”´                Can't match to N!    â”‚
â”‚                                                                         â”‚
â”‚    Result: Odometry JUMPS or FAILS completely!                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Actual Results

**Slow motion (working):**
```yaml
# Smooth position updates
position: {x: 0.10, y: 0.02, z: 0.01}
position: {x: 0.12, y: 0.03, z: 0.01}
position: {x: 0.14, y: 0.04, z: 0.02}
# Rate: 30 Hz âœ“
```

**Fast shake (failure):**
```yaml
# Position JUMPS
position: {x: 0.14, y: 0.04, z: 0.02}
position: {x: 0.85, y: -0.32, z: 0.47}  # â† JUMP!
# Or: No output at all for 500ms+ (tracking lost)
```

### RTAB-Map Warning Messages

Watch the terminal for warnings:

```
[WARN] [rtabmap.rtabmap]: Visual odometry lost! Features: 12 (minimum: 20)
[WARN] [rtabmap.rtabmap]: Motion estimation failed, odometry reset.
```

### Eureka Moment #8

::: {.callout-tip}
## Vision Fails on Fast Motion

**Why it fails:**
1. Camera captures at 30 FPS = 33ms between frames
2. Fast motion = large displacement between frames
3. Motion blur destroys features
4. Feature matching fails â†’ tracking lost

**What IMU provides:**
- IMU runs at 400 Hz = 2.5ms between samples
- IMU is immune to motion blur
- IMU can "predict" camera pose during blur

This is exactly what fusion solves in Part 3!
:::

---

## Experiment 9: Textureless Surfaces = No Features

### What You'll Experience

Visual odometry needs **visual features** (corners, edges, textures). Point the camera at a blank wall and watch it fail!

### The Test

Point the D435i at different surfaces:

1. **Textured surface** (bookshelf, posters) - should work
2. **Plain white wall** - expect failure
3. **Uniform floor/ceiling** - expect failure

### Procedure

```bash
# Monitor feature count (if RTAB-Map exposes it)
ros2 topic echo /rtabmap/info --field word_count

# Or watch for warnings
# Terminal running rtabmap_launch will show warnings
```

### What Happens

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FEATURE DETECTION vs SURFACE TEXTURE                  â”‚
â”‚                                                                         â”‚
â”‚    Textured Scene                    Textureless Scene                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚    â”‚ â˜…  ğŸ“š  â˜…  ğŸ–¼ï¸  â”‚              â”‚                 â”‚                â”‚
â”‚    â”‚    â˜…     â˜…    â”‚              â”‚                 â”‚                â”‚
â”‚    â”‚  ğŸ“·  â˜…   â˜… ğŸª´ â”‚              â”‚                 â”‚                â”‚
â”‚    â”‚ â˜…    â˜…     â˜…  â”‚              â”‚                 â”‚                â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚    Features: 150+ âœ…                Features: 3 âŒ                     â”‚
â”‚    Tracking: STABLE                  Tracking: FAILS                   â”‚
â”‚                                                                         â”‚
â”‚    Visual odometry needs features to track!                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Typical Warning Messages

```
[WARN] [rtabmap]: Not enough features detected: 8 (min: 20).
                  Visual odometry may fail.
[ERROR] [rtabmap]: Visual odometry lost! Insufficient feature matches.
```

### Real-World Failure Scenarios

| Environment | Feature Count | Tracking |
|-------------|---------------|----------|
| Office with posters | 200+ | âœ… Excellent |
| Bookshelf | 150+ | âœ… Good |
| Kitchen counter | 80-120 | âš ï¸ OK |
| Plain painted wall | 5-15 | âŒ Fails |
| White ceiling | 0-5 | âŒ Fails |
| Carpet floor | 20-40 | âš ï¸ Marginal |

### Eureka Moment #9

::: {.callout-tip}
## Vision Needs Visual Features

**Why it fails:**
- Feature detectors (ORB, SIFT) need corners/edges
- Blank walls have no distinctive points
- Can't match what doesn't exist!

**What IMU provides:**
- IMU measures motion directly from physics
- Works regardless of what camera sees
- Can track through textureless regions

**Real robot scenarios:**
- Warehouse: long plain corridors
- Hospital: white walls everywhere
- Factory: uniform floors
- Outside: blue sky, open fields
:::

---

## Experiment 10: Lighting Changes = Drift

### What You'll Experience

Visual features depend on pixel values. Lighting changes alter those values, causing feature matching to degrade.

### The Test

```bash
# Start with normal room lighting
# Monitor odometry position

# Then:
# 1. Turn lights off
# 2. Walk toward/away from window
# 3. Point camera at light source then away
```

### What Happens

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LIGHTING CHANGES vs VISUAL ODOMETRY                   â”‚
â”‚                                                                         â”‚
â”‚    Before (normal light)           After (auto-exposure change)        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚ â˜…(200,200,200)  â”‚            â”‚ â˜…(100,100,100)  â”‚                  â”‚
â”‚    â”‚    â˜…(180,180,180)â”‚   â”€â”€â–º    â”‚    â˜…(90,90,90)  â”‚                   â”‚
â”‚    â”‚ â˜…(210,210,210)  â”‚            â”‚ â˜…(105,105,105)  â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                         â”‚
â”‚    Same features, different pixel values!                              â”‚
â”‚    Feature descriptor matching becomes unreliable.                     â”‚
â”‚                                                                         â”‚
â”‚    Results:                                                            â”‚
â”‚    â€¢ Fewer matches than expected                                       â”‚
â”‚    â€¢ More outliers/bad matches                                         â”‚
â”‚    â€¢ Gradual drift or sudden jumps                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### D435i Auto-Exposure

The RealSense camera adjusts exposure automatically, which can cause:

```bash
# Check current exposure
ros2 topic echo /camera/camera/color/camera_info --once

# Exposure changes show in RViz as brightness shifts
# Watch for drift when this happens
```

### Eureka Moment #10

::: {.callout-tip}
## Vision Is Affected by Lighting

**Why it happens:**
- Feature descriptors encode pixel values
- Lighting changes alter pixel values
- Same physical feature â†’ different descriptor
- Matching confidence drops

**What IMU provides:**
- IMU measures acceleration and rotation
- Completely independent of lighting
- Works in complete darkness!

**This matters for robots:**
- Day/night transitions
- Indoor/outdoor transitions
- Moving shadows
- Flickering lights
:::

---

## The Opposite Weaknesses Pattern

Now we can see the beautiful symmetry between IMU and vision problems:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IMU vs VISION: OPPOSITE WEAKNESSES                         â”‚
â”‚                                                                         â”‚
â”‚                        IMU                        VISION                â”‚
â”‚                        â”€â”€â”€                        â”€â”€â”€â”€â”€â”€                â”‚
â”‚                                                                         â”‚
â”‚    Fast Motion:        âœ… Excellent               âŒ Fails (blur)      â”‚
â”‚                        (400 Hz sampling)          (feature loss)       â”‚
â”‚                                                                         â”‚
â”‚    Slow Motion:        âš ï¸ Drifts                  âœ… Excellent         â”‚
â”‚                        (integration error)        (clear features)     â”‚
â”‚                                                                         â”‚
â”‚    Textureless:        âœ… Works                   âŒ Fails             â”‚
â”‚                        (physics-based)            (no features)        â”‚
â”‚                                                                         â”‚
â”‚    Darkness:           âœ… Works                   âŒ Fails             â”‚
â”‚                        (no light needed)          (camera blind)       â”‚
â”‚                                                                         â”‚
â”‚    Long Duration:      âŒ Fails                   âœ… Loop closure      â”‚
â”‚                        (unbounded drift)          (corrects drift)     â”‚
â”‚                                                                         â”‚
â”‚    Absolute Yaw:       âŒ No reference            âœ… Map-relative      â”‚
â”‚                        (needs magnetometer)       (visual landmarks)   â”‚
â”‚                                                                         â”‚
â”‚                                                                         â”‚
â”‚           These are COMPLEMENTARY failure modes!                       â”‚
â”‚           Fusion can leverage the strengths of both!                   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comparison Table

| Scenario | IMU Alone | Vision Alone | Fusion (VIO) |
|----------|-----------|--------------|--------------|
| Stationary | âœ… OK (filtered) | âœ… OK | âœ… OK |
| Slow motion | âš ï¸ Drifts | âœ… Excellent | âœ… Excellent |
| **Fast motion** | âœ… OK | âŒ **Fails** | âœ… **IMU rescues** |
| **Textureless** | âœ… OK (short term) | âŒ **Fails** | âœ… **IMU bridges** |
| **Darkness** | âœ… OK | âŒ **Fails** | âš ï¸ IMU only |
| Long duration | âŒ Fails | âš ï¸ Loop closure helps | âœ… Best of both |

---

## The Math Doesn't Work: Why We Need Both

### IMU Integration Grows Error

```
Position error from IMU âˆ tÂ²

With 0.01 m/sÂ² bias:
â€¢ After 10s: ~0.5m error
â€¢ After 60s: ~18m error
â€¢ After 5 min: ~450m error!

IMU needs periodic "corrections" from an absolute source.
```

### Vision Needs Continuous Features

```
Visual odometry gap = no features for N frames

If camera sees blank wall for 1 second (30 frames):
â€¢ No feature matches possible
â€¢ Odometry output: NOTHING or WRONG
â€¢ Robot has no idea where it went

Vision needs something to "fill the gaps" during feature-less periods.
```

### The Solution Preview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHY FUSION WORKS                                     â”‚
â”‚                                                                         â”‚
â”‚    Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º      â”‚
â”‚                                                                         â”‚
â”‚    IMU:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚
â”‚            Always available, but drifting over time                    â”‚
â”‚                                                                         â”‚
â”‚    Vision: â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–“â–“â–“â–“â–“â–“â–“â–“â–“          â”‚
â”‚            Sometimes lost (fast motion, textureless)                   â”‚
â”‚                                                                         â”‚
â”‚    VIO:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚
â”‚            IMU: continuous prediction                                   â”‚
â”‚            Vision: periodic correction                                  â”‚
â”‚            Result: STABLE, CONTINUOUS pose estimation!                 â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary: Vision-Only Failures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PART 2 SUMMARY: WHY VISION ALONE FAILS                     â”‚
â”‚                                                                         â”‚
â”‚   Problem #8: Fast motion causes feature blur                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚   Symptom: Tracking lost during rapid movement                         â”‚
â”‚   Impact: Robot loses localization when moving quickly                 â”‚
â”‚                                                                         â”‚
â”‚   Problem #9: Textureless surfaces have no features                    â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚   Symptom: Tracking fails on blank walls, ceilings                     â”‚
â”‚   Impact: Robot can't navigate corridors, warehouses                   â”‚
â”‚                                                                         â”‚
â”‚   Problem #10: Lighting changes affect matching                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚   Symptom: Drift when exposure changes                                 â”‚
â”‚   Impact: Day/night, indoor/outdoor transitions fail                   â”‚
â”‚                                                                         â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                  â”‚
â”‚   KEY INSIGHT: Vision and IMU have OPPOSITE failures!                  â”‚
â”‚   This is what makes FUSION so powerful!                               â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What's Next: The Solution!

We've now experienced both:

1. **Part 1**: IMU alone â†’ drift, yaw problems
2. **Part 2**: Vision alone â†’ fast motion, textureless failures

In **Part 3**, we'll combine them into **Visual-Inertial Odometry (VIO)**:

- IMU provides high-frequency motion estimates
- Vision corrects drift periodically
- Result: Robust pose estimation that handles both failure modes!

::: {.callout-tip}
## The Preview
Part 3 experiments:
- **Experiment 11**: IMU rescues fast motion
- **Experiment 12**: Vision corrects IMU drift
- **Experiment 13**: Isaac ROS Visual SLAM with IMU
- **Experiment 14**: Complete VIO pipeline

We'll build **exactly what yDx.M + external sensors** achieves - with our D435i alone!
:::

---

## Preparation Checklist

Before Workshop 4, make sure you can:

- [ ] Launch RTAB-Map visual odometry
- [ ] Observe tracking loss during fast motion
- [ ] Understand why textureless surfaces fail
- [ ] Know the complementary nature of IMU and vision failures
- [ ] Articulate why fusion is needed

---

## About This Learning Journey

By experiencing these failures firsthand, you'll:

1. **Deeply understand** why sensor fusion exists
2. **Appreciate** what yDx.M + external sensors achieve
3. **Know when** each sensor type is reliable
4. **Debug** fusion problems by understanding individual sensor limits

The workshop will show professional solutions - we're building the foundation to understand them!

---

## Resources

- [RTAB-Map Documentation](http://wiki.ros.org/rtabmap_ros)
- [Visual Odometry Fundamentals](https://www.iro.umontreal.ca/~labMDR/papers/visual_odometry_tutorial.pdf)
- [Feature Detection Overview](https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html)
- [Why VIO Works](https://arxiv.org/abs/1906.06097) (Academic Paper)
